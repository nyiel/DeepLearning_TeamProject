{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T18:38:13.173162Z",
     "iopub.status.busy": "2025-11-02T18:38:13.172555Z",
     "iopub.status.idle": "2025-11-02T18:38:13.178741Z",
     "shell.execute_reply": "2025-11-02T18:38:13.178071Z",
     "shell.execute_reply.started": "2025-11-02T18:38:13.173136Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… TensorFlow version: 2.18.0\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# ğŸª´ Medicinal Leaf Classification - Flask-Ready Model\n",
    "# Classes: Mango, Neem, Guava, Lemon\n",
    "# Authors: (Ayuen, Malith, Deng, Biar & Akot)\n",
    "# ================================================================\n",
    "# This notebook trains a leaf classifier in two stages:\n",
    "#  1ï¸âƒ£ Base CNN from scratch\n",
    "#  2ï¸âƒ£ Transfer Learning using EfficientNetB7\n",
    "# The final model is saved for easy use in a Flask web app.\n",
    "# ================================================================\n",
    "\n",
    "# ------------------------------\n",
    "# 1. IMPORT LIBRARIES\n",
    "# ------------------------------\n",
    "import os\n",
    "import random\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import cv2\n",
    "import albumentations as A\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.applications import EfficientNetB7\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as effnet_preprocess\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print('âœ… TensorFlow version:', tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T18:38:20.487124Z",
     "iopub.status.busy": "2025-11-02T18:38:20.486604Z",
     "iopub.status.idle": "2025-11-02T18:38:20.492041Z",
     "shell.execute_reply": "2025-11-02T18:38:20.491431Z",
     "shell.execute_reply.started": "2025-11-02T18:38:20.487099Z"
    }
   },
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# 2. CONFIGURATION\n",
    "# ------------------------------\n",
    "# Adjust these paths for your environment (Kaggle or local)\n",
    "DATA_DIR = '/kaggle/input/indian-medicinal-leaves-dataset/Indian Medicinal Leaves Image Datasets/Medicinal Leaf dataset'\n",
    "WORK_DIR = '/kaggle/working/models'\n",
    "\n",
    "# Create working directory if not exists\n",
    "os.makedirs(WORK_DIR, exist_ok=True)\n",
    "\n",
    "# Image and training parameters\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS_BASE = 8\n",
    "EPOCHS_TRANSFER = 10\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Target classes (4 specific plants)\n",
    "TARGET_CLASSES = ['Mango', 'Neem', 'Guava', 'Lemon']\n",
    "\n",
    "# Set global seeds for reproducibility\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T18:38:24.682749Z",
     "iopub.status.busy": "2025-11-02T18:38:24.682134Z",
     "iopub.status.idle": "2025-11-02T18:38:26.095010Z",
     "shell.execute_reply": "2025-11-02T18:38:26.094378Z",
     "shell.execute_reply.started": "2025-11-02T18:38:24.682722Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¸ Total images found: 486\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# 3. BUILD METADATA FROM FOLDERS\n",
    "# ------------------------------\n",
    "def build_meta_from_folders(root_dir, extensions=('jpg', 'jpeg', 'png')):\n",
    "    \"\"\"\n",
    "    Scans dataset folders and returns a DataFrame with image file paths and labels.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for cls in sorted(os.listdir(root_dir)):\n",
    "        if cls not in TARGET_CLASSES:\n",
    "            continue  # Ignore unwanted classes\n",
    "        cls_path = os.path.join(root_dir, cls)\n",
    "        if not os.path.isdir(cls_path):\n",
    "            continue\n",
    "        for ext in extensions:\n",
    "            for fp in glob(os.path.join(cls_path, '**', f'*.{ext}'), recursive=True):\n",
    "                rows.append({'file_path': fp, 'label': cls})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "meta = build_meta_from_folders(DATA_DIR)\n",
    "if meta.empty:\n",
    "    raise ValueError(f\"No images found for classes {TARGET_CLASSES}\")\n",
    "\n",
    "print(f\"ğŸ“¸ Total images found: {len(meta)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T18:38:34.366945Z",
     "iopub.status.busy": "2025-11-02T18:38:34.366374Z",
     "iopub.status.idle": "2025-11-02T18:38:34.392284Z",
     "shell.execute_reply": "2025-11-02T18:38:34.389467Z",
     "shell.execute_reply.started": "2025-11-02T18:38:34.366922Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 340, Val: 73, Test: 73\n",
      "âœ… Saved class mapping â†’ class_indices.json\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# 4. SPLIT DATA INTO TRAIN/VAL/TEST\n",
    "# ------------------------------\n",
    "train_df, temp_df = train_test_split(meta, test_size=0.3, stratify=meta['label'], random_state=RANDOM_SEED)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['label'], random_state=RANDOM_SEED)\n",
    "\n",
    "print(f\"Train: {len(train_df)}, Val: {len(val_df)}, Test: {len(test_df)}\")\n",
    "\n",
    "# Encode class labels as integers\n",
    "class_names = sorted(train_df['label'].unique())\n",
    "label2idx = {c: i for i, c in enumerate(class_names)}\n",
    "\n",
    "# Save label mapping for Flask app\n",
    "with open(os.path.join(WORK_DIR, \"class_indices.json\"), \"w\") as f:\n",
    "    json.dump({\"class_names\": class_names, \"label2idx\": label2idx}, f, indent=4)\n",
    "print(\"âœ… Saved class mapping â†’ class_indices.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T18:38:43.437671Z",
     "iopub.status.busy": "2025-11-02T18:38:43.437372Z",
     "iopub.status.idle": "2025-11-02T18:38:45.295975Z",
     "shell.execute_reply": "2025-11-02T18:38:45.295348Z",
     "shell.execute_reply.started": "2025-11-02T18:38:43.437639Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "I0000 00:00:1762108723.669914      37 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# 5. DATA AUGMENTATION PIPELINES\n",
    "# ------------------------------\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(IMG_SIZE, IMG_SIZE),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=20, p=0.5),\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(IMG_SIZE, IMG_SIZE)\n",
    "])\n",
    "\n",
    "def _read_image(path):\n",
    "    \"\"\"\n",
    "    Reads and converts image to RGB.\n",
    "    \"\"\"\n",
    "    img = cv2.imread(path.decode('utf-8'))\n",
    "    if img is None:\n",
    "        return np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img\n",
    "\n",
    "def augment_image(path, label, transform):\n",
    "    \"\"\"\n",
    "    Applies augmentation (Albumentations) and scales image to [0,1].\n",
    "    \"\"\"\n",
    "    img = _read_image(path)\n",
    "    augmented = transform(image=img)\n",
    "    img = augmented['image'].astype('float32') / 255.0\n",
    "    return img, label\n",
    "\n",
    "def tf_augment(path, label, train=True):\n",
    "    \"\"\"\n",
    "    Wraps Python image augmentations for TensorFlow Dataset.\n",
    "    \"\"\"\n",
    "    fn = lambda p, l: augment_image(p, l, train_transform if train else val_transform)\n",
    "    img, lbl = tf.numpy_function(fn, [path, label], [tf.float32, tf.int64])\n",
    "    img.set_shape((IMG_SIZE, IMG_SIZE, 3))\n",
    "    lbl.set_shape(())\n",
    "    return img, lbl\n",
    "\n",
    "def df_to_dataset(df, batch_size=BATCH_SIZE, shuffle=True, train=True):\n",
    "    \"\"\"\n",
    "    Converts DataFrame into tf.data.Dataset with augmentations.\n",
    "    \"\"\"\n",
    "    paths = df['file_path'].astype(str).values\n",
    "    labels = df['label'].map(label2idx).astype(np.int64).values\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(paths), seed=RANDOM_SEED)\n",
    "    ds = ds.map(lambda p, l: tf_augment(p, l, train=train), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = df_to_dataset(train_df, train=True)\n",
    "val_dataset = df_to_dataset(val_df, train=False)\n",
    "test_dataset = df_to_dataset(test_df, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T18:38:53.100114Z",
     "iopub.status.busy": "2025-11-02T18:38:53.099537Z",
     "iopub.status.idle": "2025-11-02T18:39:10.264910Z",
     "shell.execute_reply": "2025-11-02T18:39:10.264352Z",
     "shell.execute_reply.started": "2025-11-02T18:38:53.100091Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Training Base CNN...\n",
      "\n",
      "Epoch 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1762108736.103825     103 service.cc:148] XLA service 0x78aa94087840 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1762108736.104648     103 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
      "I0000 00:00:1762108736.463684     103 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 6/22\u001b[0m \u001b[32mâ”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2816 - loss: 1.3972"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762108739.380979     103 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 194ms/step - accuracy: 0.2803 - loss: 1.3899 - val_accuracy: 0.2740 - val_loss: 1.3794\n",
      "Epoch 2/8\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.3240 - loss: 1.3714 - val_accuracy: 0.3014 - val_loss: 1.3640\n",
      "Epoch 3/8\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.2762 - loss: 1.3757 - val_accuracy: 0.2740 - val_loss: 1.3653\n",
      "Epoch 4/8\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.3284 - loss: 1.3679 - val_accuracy: 0.2877 - val_loss: 1.3498\n",
      "Epoch 5/8\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.3741 - loss: 1.3368 - val_accuracy: 0.4384 - val_loss: 1.2888\n",
      "Epoch 6/8\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.3996 - loss: 1.2814 - val_accuracy: 0.3425 - val_loss: 1.2807\n",
      "Epoch 7/8\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.4105 - loss: 1.2736 - val_accuracy: 0.5205 - val_loss: 1.2069\n",
      "Epoch 8/8\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.4147 - loss: 1.2284 - val_accuracy: 0.4521 - val_loss: 1.1545\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# 6. BASE CNN MODEL (Stage 1)\n",
    "# ------------------------------\n",
    "def build_base_model(input_shape=(IMG_SIZE, IMG_SIZE, 3), n_classes=len(class_names)):\n",
    "    \"\"\"\n",
    "    Simple CNN baseline for initial training.\n",
    "    \"\"\"\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, 3, activation='relu', padding='same')(inputs)\n",
    "    x = layers.MaxPool2D()(x)\n",
    "    x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPool2D()(x)\n",
    "    x = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(n_classes, activation='softmax')(x)\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "base_model = build_base_model()\n",
    "base_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "callbacks_base = [\n",
    "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    ModelCheckpoint(os.path.join(WORK_DIR, 'base_model.keras'), save_best_only=True, monitor='val_loss')\n",
    "]\n",
    "\n",
    "print(\"\\nğŸš€ Training Base CNN...\\n\")\n",
    "history_base = base_model.fit(train_dataset, validation_data=val_dataset, epochs=EPOCHS_BASE, callbacks=callbacks_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T18:42:15.858294Z",
     "iopub.status.busy": "2025-11-02T18:42:15.857695Z",
     "iopub.status.idle": "2025-11-02T18:45:36.009358Z",
     "shell.execute_reply": "2025-11-02T18:45:36.008717Z",
     "shell.execute_reply.started": "2025-11-02T18:42:15.858267Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb7_notop.h5\n",
      "\u001b[1m258076736/258076736\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
      "\n",
      "ğŸŒ± Training EfficientNetB7 (Frozen base)...\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 3s/step - accuracy: 0.3954 - loss: 1.3273 - val_accuracy: 0.7808 - val_loss: 0.8109\n",
      "Epoch 2/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 258ms/step - accuracy: 0.7572 - loss: 0.8269 - val_accuracy: 0.8493 - val_loss: 0.6081\n",
      "Epoch 3/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 300ms/step - accuracy: 0.7737 - loss: 0.6640 - val_accuracy: 0.8493 - val_loss: 0.5029\n",
      "Epoch 4/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 257ms/step - accuracy: 0.8744 - loss: 0.4944 - val_accuracy: 0.8630 - val_loss: 0.4463\n",
      "Epoch 5/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 258ms/step - accuracy: 0.8803 - loss: 0.4207 - val_accuracy: 0.8630 - val_loss: 0.4160\n",
      "Epoch 6/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 256ms/step - accuracy: 0.8807 - loss: 0.4434 - val_accuracy: 0.9041 - val_loss: 0.3807\n",
      "Epoch 7/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 257ms/step - accuracy: 0.9086 - loss: 0.3263 - val_accuracy: 0.8767 - val_loss: 0.3521\n",
      "Epoch 8/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 261ms/step - accuracy: 0.8979 - loss: 0.3630 - val_accuracy: 0.9178 - val_loss: 0.3368\n",
      "Epoch 9/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 256ms/step - accuracy: 0.9132 - loss: 0.3235 - val_accuracy: 0.9178 - val_loss: 0.3206\n",
      "Epoch 10/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 259ms/step - accuracy: 0.8953 - loss: 0.3156 - val_accuracy: 0.9178 - val_loss: 0.3114\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# 7. EFFICIENTNETB7 TRANSFER LEARNING (Stage 2)\n",
    "# ------------------------------\n",
    "def build_efficientnet_model(n_classes=len(class_names)):\n",
    "    \"\"\"\n",
    "    Builds EfficientNetB7-based model for transfer learning.\n",
    "    \"\"\"\n",
    "    base = EfficientNetB7(include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3), pooling='avg')\n",
    "    base.trainable = False  # Freeze base initially\n",
    "\n",
    "    inputs = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    x = effnet_preprocess(inputs * 255.0)\n",
    "    x = base(x, training=False)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    outputs = layers.Dense(n_classes, activation='softmax')(x)\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "effnet_model = build_efficientnet_model()\n",
    "effnet_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "callbacks_effnet = [\n",
    "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    ModelCheckpoint(os.path.join(WORK_DIR, 'efficientnet_stage1.keras'), save_best_only=True, monitor='val_loss')\n",
    "]\n",
    "\n",
    "print(\"\\nğŸŒ± Training EfficientNetB7 (Frozen base)...\\n\")\n",
    "history_effnet = effnet_model.fit(train_dataset, validation_data=val_dataset, epochs=EPOCHS_TRANSFER, callbacks=callbacks_effnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T18:50:22.448705Z",
     "iopub.status.busy": "2025-11-02T18:50:22.448391Z",
     "iopub.status.idle": "2025-11-02T18:57:32.295894Z",
     "shell.execute_reply": "2025-11-02T18:57:32.295274Z",
     "shell.execute_reply.started": "2025-11-02T18:50:22.448684Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”§ Fine-tuning EfficientNetB7...\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1762109639.412407     105 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1762109639.608624     105 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1762109639.998312     105 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1762109640.200974     105 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1762109640.701092     105 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1762109640.922190     105 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1762109641.576863     105 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1762109641.836309     105 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1762109642.368287     105 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1762109642.629347     105 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1762109643.599723     105 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1762109643.933002     105 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m21/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 372ms/step - accuracy: 0.6736 - loss: 0.8573"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1762109741.160307     106 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1762109741.359651     106 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1762109741.713771     106 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1762109741.932991     106 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1762109742.515294     106 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1762109742.774622     106 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m404s\u001b[0m 6s/step - accuracy: 0.6738 - loss: 0.8557 - val_accuracy: 0.9041 - val_loss: 0.3090\n",
      "Epoch 2/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 387ms/step - accuracy: 0.7340 - loss: 0.7549 - val_accuracy: 0.8904 - val_loss: 0.3169\n",
      "Epoch 3/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 384ms/step - accuracy: 0.7685 - loss: 0.6436 - val_accuracy: 0.8630 - val_loss: 0.3407\n",
      "Epoch 4/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 385ms/step - accuracy: 0.8382 - loss: 0.5285 - val_accuracy: 0.8356 - val_loss: 0.3610\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# 8. FINE-TUNING EFFICIENTNETB7\n",
    "# ------------------------------\n",
    "# Unfreeze base model for fine-tuning\n",
    "effnet_model.get_layer(index=1).trainable = True\n",
    "effnet_model.compile(optimizer=keras.optimizers.Adam(1e-5), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "callbacks_finetune = [\n",
    "    EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
    "    ModelCheckpoint(os.path.join(WORK_DIR, 'efficientnet_finetuned.keras'), save_best_only=True, monitor='val_loss')\n",
    "]\n",
    "\n",
    "print(\"\\nğŸ”§ Fine-tuning EfficientNetB7...\\n\")\n",
    "history_finetune = effnet_model.fit(train_dataset, validation_data=val_dataset, epochs=EPOCHS_TRANSFER, callbacks=callbacks_finetune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T19:00:54.940227Z",
     "iopub.status.busy": "2025-11-02T19:00:54.939608Z",
     "iopub.status.idle": "2025-11-02T19:00:57.943811Z",
     "shell.execute_reply": "2025-11-02T19:00:57.943140Z",
     "shell.execute_reply.started": "2025-11-02T19:00:54.940185Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Final model saved for Flask: /kaggle/working/models/model_final_flask.h5\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# 9. SAVE FINAL MODEL FOR FLASK\n",
    "# ------------------------------\n",
    "final_model_path = os.path.join(WORK_DIR, 'model_final_flask.h5')\n",
    "effnet_model.save(final_model_path)\n",
    "print(\"âœ… Final model saved for Flask:\", final_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T19:01:29.019092Z",
     "iopub.status.busy": "2025-11-02T19:01:29.018230Z",
     "iopub.status.idle": "2025-11-02T19:02:06.848008Z",
     "shell.execute_reply": "2025-11-02T19:02:06.847130Z",
     "shell.execute_reply.started": "2025-11-02T19:01:29.019052Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step\n",
      "\n",
      "ğŸ“Š Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Guava       0.85      0.89      0.87        19\n",
      "       Lemon       1.00      0.89      0.94        19\n",
      "       Mango       0.82      0.93      0.87        15\n",
      "        Neem       1.00      0.95      0.97        20\n",
      "\n",
      "    accuracy                           0.92        73\n",
      "   macro avg       0.92      0.92      0.92        73\n",
      "weighted avg       0.92      0.92      0.92        73\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# 10. EVALUATION\n",
    "# ------------------------------\n",
    "y_true, y_pred = [], []\n",
    "for imgs, lbls in test_dataset:\n",
    "    preds = effnet_model.predict(imgs)\n",
    "    y_true.extend(lbls.numpy().tolist())\n",
    "    y_pred.extend(np.argmax(preds, axis=1).tolist())\n",
    "\n",
    "print(\"\\nğŸ“Š Classification Report:\\n\")\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 3701557,
     "sourceId": 6417582,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
